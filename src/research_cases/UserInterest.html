<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Uruguay Results</title>
    <link rel="stylesheet" href="../../styles.css">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/flat-ui/2.2.2/css/flat-ui.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css">
</head>

<body>
    <nav class="navbar navbar-inverse navbar-fixed-top transparent">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar"
                    aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                </button>
                <a class="navbar-brand" href="../../index.html">Team # 2 AI Portfolio</a>
            </div>
            <div class="collapse navbar-collapse" id="navbar">
                <ul class="nav navbar-nav navbar-right">
                    <li><a href="#about">About</a></li>
                    <li><a href="#portfolio">Portfolio</a></li>
                    <li><a href="#contact">Contact</a></li>
                </ul>
            </div>
        </div>
    </nav>
    <main data-bs-spy="scroll" data-bs-target=".navbar" data-bs-offset="50">
        <div class="container">
            <div class="row mb-5">
                <div class="col-md-12">
                    <h4 style="text-align: center;">Predict of Uruguay football match results</h4>
                    <div class="d-flex justify-content-center align-items-center">
                        <img src="Assets/research_images/lucho.jpg" class="img-fluid">
                    </div>
                    <p><strong>Introduction:</strong><br>
                        Based on the Kaggle dataset available in <a
                            href="https://www.kaggle.com/datasets/arindamsahoo/social-media-users"
                            target="_blank">Social-Media-Users-Dataset</a>, este proyecto tiene como objetivo desarrollar una metodología para segmentar a los usuarios de una red social según sus intereses comunes. 
                            La segmentación permitirá sugerir conexiones entre usuarios con afinidades similares, facilitando la creación de comunidades más significativas y mejorando la experiencia de usuario. 
                            La segmentación por intereses no solo aumenta la probabilidad de conexiones exitosas, sino que también optimiza el contenido recomendado en función de lo que los usuarios valoran y comparten en común.
                            Este dataset cuenta con mas de 100.000 filas lo cual es ideal para este análisis.
                    </p>
                    <p><strong>Why did I choose this case study?</strong><br>
                        Elegí este caso para estudiar porque la segmentación de usuarios en redes sociales es un tema de gran relevancia en el mundo digital actual. 
                        En un entorno donde las plataformas compiten por captar y retener usuarios, ofrecer experiencias personalizadas se ha convertido en una estrategia clave. 
                        La agrupación de usuarios por intereses comunes no solo permite mejorar las recomendaciones de amistad y contenido, sino que también fomenta interacciones significativas y la creación de comunidades virtuales que enriquecen la experiencia de los usuarios.
                    </p>
                    <p><strong>Objectives:</strong><br>
                        El enfoque de este proyecto es agrupar a los usuarios en función de sus intereses comunes. Al identificar grupos de usuarios con intereses similares a través de algún algoritmo de aprendizaje no supervisado.
                    </p>
                    <h5>Development</h5>
                    <h6>Analysis of attributes and their distributions:</h6>
                    <ul>

                        <li><strong>UserID:</strong> Id del usuario.<br>
                            Tiene una distribución uniforme (cada usuario tiene un ID único, sin valores repetidos).
                        </li>

                        <li><strong>Name:</strong> Nombre del usuario.<br>
                            No se identifican valores nulos ni vacíos.
                        </li>

                        <li><strong>Gender:</strong> Representa el género de los usuarios: "Male" y "Female".<br>
                            La proporción entre "Male" y "Female" está cercana al 50-50, lo que indica una distribución binomial casi equilibrada. 
                            La distribución es ligeramente asimétrica hacia el género "Female", aunque la diferencia es mínima.
                        </li>
                        <div class="d-flex justify-content-start align-items-start">
                            <img src="../../Assets/research_images/userInterestAssets/image.png" class="img-fluid" style="width: 30%;">
                        </div>
                        <li><strong>DOB:</strong> Fecha de nacimiento de los usuarios.<br>
                            En base a este atributo podriamos calcular la edad de cada usuario si fuese necesario.
                            Al calcular la edad de los usuarios en un año específico (por ejemplo, 2024), las edades oscilarían entre: 20 años (nacidos en 2004) y 70 años (nacidos en 1954).
                            Las edades siguen una distribución asimétrica hacia la derecha es decir, hay más usuarios jóvenes de entre 20 y 40 años que usuarios mayores a 50 años.
                        </li>
                        <div class="d-flex justify-content-start align-items-start">
                            <img src="../../Assets/research_images/userInterestAssets/imageDOB.png" class="img-fluid" style="width: 30%;">
                        </div>

                        <li><strong>Interests:</strong> Lista de intereses por usuario.<br>
                            La distribución de los intereses en este dataset proporciona una perspectiva clave sobre la variedad y frecuencia de los intereses entre los usuarios de redes sociales. 
                            Este análisis es crucial para entender las preferencias generales de los usuarios y cómo estos intereses pueden agruparse para generar recomendaciones personalizadas.
                            Los intereses están representados como un atributo polinómico, donde cada usuario puede tener una o más etiquetas de interés asociadas.

                            Algunos usuarios tienen un único interés mientras que otros tienen varios. Esto puede analizarse agrupando a los usuarios por la cantidad de intereses listados.

                            Es posible contar cuántas veces aparece cada interés o conjunto de intereses en el dataset. Por ejemplo: "Fashion": 142 ocurrencias.
                        </li>
                        <div class="d-flex justify-content-start align-items-start">
                            <img src="../../Assets/research_images/userInterestAssets/imageInterest.png" class="img-fluid" style="width: 30%;">
                        </div>

                        <li><strong>City:</strong> Ciudad donde reside cada usuario.<br>
                            La distribución de las ciudades está altamente sesgada, ya que la mayoría de las ciudades tienen un solo usuario registrado, solo unas pocas ciudades tienen más de un usuario, lo cual es 
                            representativo de una dispersión poblacional amplia.
                        </li>
                        <div class="d-flex justify-content-start align-items-start">
                            <img src="../../Assets/research_images/userInterestAssets/city.png"class="img-fluid" style="width: 30%;">
                        </div>
                        <div class="d-flex justify-content-start align-items-start">
                            <img src="../../Assets/research_images/userInterestAssets/city2.png"class="img-fluid" style="width: 30%;">
                        </div>

                        <li><strong>Country:</strong> País donde reside el usuario<br>
                            La distribución es positivamente sesgada dado que un pequeño grupo de países acumula la mayor cantidad de registros.
                            La cola de la distribución muestra una gran cantidad de países con pocos registros, lo que es común en datasets de este tipo donde ciertas ubicaciones son más prominentes.
                            No se identifican valores atípicos claros en la distribución. Los registros de países menos frecuentes son consistentes con la naturaleza del dataset.
                        </li>
                        <div class="d-flex justify-content-start align-items-start">
                            <img src="../../Assets/research_images/userInterestAssets/country.png" class="img-fluid" style="width: 30%;">
                        </div>
                    </ul>

                    <h5>K-Means Model Application</h5>
                    <p>Proceso creando en RapidMiner con el algoritmo Kmeans para segmentar a los usuarios de una red social según sus intereses comunes.</p>
                    <div class="d-flex justify-content-start align-items-start">
                        <img src="../../Assets/research_images/userInterestAssets/allProcess.png" class="img-fluid"
                            style="width: 60%;">
                        </div>

                    <p>Sub proceso dentro de "Loop Parameters".</p>
                    <div class="d-flex justify-content-start align-items-start">
                        <img src="../../Assets/research_images/userInterestAssets/subProcess.png" class="img-fluid"
                            style="width: 60%;">
                        </div>

                    <p>1. Sample
                        Su proposito es extraer una muestra de datos del conjunto original.
                        Este operador se utiliza generalmente para manejar un subconjunto más manejable de datos cuando el dataset original es muy grande, permitiendo pruebas rápidas y evitando problemas de rendimiento.
                    </p>

                    <p>2. Remove Duplicates
                       Su proposito es eliminar registros duplicados del conjunto de datos.
                        Los duplicados pueden sesgar los resultados del clustering al hacer que ciertos clusters parezcan más densos de lo que realmente son.
                    </p>

                    <p>3. Date to Numerical
                        El propósito es convertir atributos de tipo fecha (como DOB) a valores numéricos.
                        Razón: Los algoritmos de clustering no pueden manejar directamente datos de tipo fecha. En este caso, se utilizó para calcular la edad a partir del año de nacimiento.
                    </p>

                    <p>4. Generate Attributes
                        El proposito es crear atributos derivados basados en cálculos.
                        Este bloque se utilizó para calcular la edad del usuario a partir de la fecha de nacimiento (DOB), transformándola en un atributo numérico relevante para el clustering.
                    </p>

                    <p>5. Select Attributes
                        El proposito es seleccionar los atributos relevantes para el análisis.
                        Razón: El clustering funciona mejor con atributos significativos. por lo que seleccionamos Age, Interests, y Gender como los más relevantes para la segmentación.
                    </p>

                    <p>6. Nominal to Numerical
                        El proposito es convertir atributos categóricos (nominales) a un formato numérico.
                        K-Means requiere que todos los atributos sean numéricos para calcular distancias entre puntos.
                    </p>

                    <p>7. Normalize
                        El proposito es escalar los atributos numéricos a un rango común (por ejemplo, [0,1] o valores z-estandarizados).
                        K-Means es sensible a la escala de los atributos. La normalización asegura que ningún atributo domine el cálculo de distancias debido a un rango más amplio de valores.
                    </p>

                    <p>8. Loop Parameters
                       El proposito es aplicar y optimizar el algoritmo de clustering.
                       Este operador se utiliza para realizar un análisis iterativo sobre diferentes configuraciones del algoritmo, como el número de clusters k.
                       Se configura el rango de valores para k y evaluar el desempeño de cada modelo basado en métricas como el codo de la curva (elbow method) o la distancia entre clusters.
                    </p>

                    <p>9. K-Means Clustering
                        El porposito es agrupar los datos en k clusters basados en similitudes entre los atributos seleccionados.
                        Este paso genera los clusters finales y proporciona la asignación de cada registro a un cluster.
                        Se debe terminar el número óptimo de clusters (k) basado en pruebas anteriores. Se utiliza la distancia euclidiana para medir la similitud entre puntos.
                    </p>



                    <h5>Selección del parametro k en K-Means</h5>
                    <p>
                        El operador Loop Parameters es clave para realizar experimentos iterativos con diferentes configuraciones de parámetros. En el caso del algoritmo de K-Means, 
                        este operador permite probar diferentes valores de k para determinar cuál es el más adecuado.

                        En este caso utilizamos el metodo denominado "Elbow Method". Es una técnica visual utilizada para determinar el número óptimo de clusters (k) en algoritmos de clustering

                        Para realizar este método debemos configurar el operador de Cluster Distance Performance para calcular la métrica de "Avg. within centroid distance" en cada iteración.

                        El eje "x" representa el número de clusters k y el eje "y" representa la métrica "Avg. within centroid distance" calculada para cada k.

                        En este caso, ajustamos el operador "Loop Parameters" para explorar desde k = 2 hasta k = 100 con 30 steps.
                    </p>

                    <div class="d-flex justify-content-start align-items-start">
                        <img src="../../Assets/research_images/userInterestAssets/elbow.png" class="img-fluid"
                            style="width: 60%;">
                    </div>

                    <p>
                        Una vez creada la representación grafica, podemos observar que La gráfica sigue una tendencia decreciente, lo que es esperado. A medida que aumenta el número de clusters, 
                        la distancia promedio al centroide disminuye porque hay más clusters para capturar las variaciones dentro de los datos.

                        El "codo" es el punto en el cual la reducción en la distancia promedio comienza a ser menos significativa. En este caso, el codo parece encontrarse alrededor de k = 15. Esto significa que hasta 
                        k = 15 agregar más clusters resulta en una mejora sustancial en la compactación de los clusters. Más allá de k=15, la mejora es marginal.

                        Si tomamos k = 15 balancea una buena segmentación de los datos sin sobreajustar (demasiados clusters).

                    </p>

                    <h5>Luego de ejecutar el algoritmo obtenemos el siguiente resultado</h5>
                    <div class="d-flex justify-content-start align-items-start">
                        <img src="../../Assets/research_images/userInterestAssets/clusters.png" class="img-fluid"
                            style="width: 60%;">
                    </div>

                    <p>El eje "x" representa la característica "Interests" de los datos, previamente normalizada y El eje "y" representa la característica "Age" también normalizada.
                        Cada color denota un cluster único, con un total de 15 clusters representados.
                        Los clusters parecen estar distribuidos de forma razonable, con diferenciación visible en ciertas regiones. Sin embargo, algunos clusters parecen solaparse o tener menos separación clara.
                        Esto se debe a la naturaleza de los datos ya que pueden haber personas de diferentes edades con los mismos intereses o viceversa, estos atributos no son completamente independientes ni perfectamente discriminantes.
                    </p>

                    <div class="d-flex justify-content-start align-items-start">
                        <img src="../../Assets/research_images/userInterestAssets/clustersGender.png" class="img-fluid"
                            style="width: 60%;">
                    </div>

                    <p>En este caso, el eje "x" representa la característica "Interests" de los datos, previamente normalizada y El eje "y" representa la característica "Gender".
                        Cada color denota un cluster único, con un total de 15 clusters representados.
                        La separación clara en dos líneas horizontales (-1 y 1) indica que los datos se distribuyen únicamente entre dos géneros, lo que significa que el atributo no tiene valores intermedios.
                        También se observa que los colores de los clusters están mezclados dentro de los valores de Interests, lo que indica que los intereses no son un atributo completamente discriminante para separar los clusters, esto es un reflejo de la naturaleza de los datos, donde diferentes personas comparten intereses similares independientemente del género.
                        Algunos clusters ocupan rangos amplios en el eje de Interests, lo que sugiere una mayor diversidad en los intereses dentro de esos grupos.
                    </p>
                    <h6>Comparison of Confusion Matrices:</h6>
                    <ul>
                        <li><strong>Overall accuracy improvement:</strong> Increased from 49.82% to 65.61%, indicating
                            better model performance by removing irrelevant attributes.</li>
                        <li><strong>Class precision:</strong> The precision of the "Won" class improved from 60.18% to
                            70.63%, and the "Lost" class increased from 55.56% to 73.68%. The "Draw" class also
                            improved, going from 29.27% to 50.60%.</li>
                    </ul>
                    <h5>Other Feature Selection Techniques</h5>
                    <ul>
                        <li>The Backward Elimination technique improved accuracy, but was inferior to Forward Selection.
                        </li>
                        <li>Optimize Selection matched Forward Selection's accuracy but did not exceed it.</li>
                    </ul>

                    <h5>Now lets try with decision tree</h5>
                    <div class="d-flex justify-content-start align-items-start">
                        <img src="../../Assets/research_images/decision_process.png" class="img-fluid"
                            style="width: 60%;">
                    </div>
                    <p>After run process, it shows a new matrix</p>
                    <div class="d-flex justify-content-start align-items-start">
                        <img src="../../Assets/research_images/decision_tree.png" class="img-fluid">
                    </div>
                </div>
            </div>
        </div>

        <div class="container mt-5">
            <h4 class="mb-4">Conclusion</h4>
            <h6>Decision Tree vs. Naive Bayes for Predicting Uruguay's Match Outcomes</h6>
            <p>
                After incorporating a Decision Tree model alongside the Naive Bayes model, the results showed that the
                Decision Tree yielded a lower accuracy compared to the Naive Bayes approach. This suggests that, for
                this particular dataset, Naive Bayes is better at capturing the underlying patterns in the match data of
                Uruguay.
            </p>
            <h4>Possible Reasons:</h4>
            <ul>
                <li><strong>Feature Independence:</strong> Naive Bayes assumes that all features are independent, which,
                    despite being a strong assumption, can perform well when the assumption holds reasonably true. It
                    might be more suitable for this dataset if the input features do not have strong interactions.</li>
                <li><strong>Decision Boundaries:</strong> Decision Trees tend to create hard splits and might struggle
                    when the decision boundaries between winning, losing, and drawing are not well-defined in the
                    feature space. This can lead to overfitting in the training set, causing a decrease in performance
                    on unseen data.</li>
                <li><strong>Data Distribution:</strong> The nature of football match results (win, draw, lose) may be
                    better modeled by the probabilistic approach of Naive Bayes, especially given the skewed
                    distributions in some features like scores.</li>
            </ul>
            <h4>Recommendation:</h4>
            <p>
                While Decision Trees offer interpretability by showing how different features influence outcomes, Naive
                Bayes seems more effective for this specific problem in terms of accuracy. To further improve model
                performance, it could be beneficial to try ensemble methods like Random Forests, which combine multiple
                decision trees and often provide better predictive power.
            </p>
            <p>
                Additionally, exploring other classification models such as Support Vector Machines (SVM) or even deep
                learning techniques could yield better results in predicting match outcomes.
            </p>
        </div>

        <div class="container mt-5 mb-3">
            <h3 class="text-center">Web bibliography</h3>
            <hr>
            <p>
                https://www.tenfield.com.uy/suarez-leyenda/
            </p>
        </div>
    </main>

    <div class="text-center text-inverse navbar-inverse">
        <div class="container">
            <div class="row">
                <div class="footer-col col-md-4" id="contact">
                    <h3>Location</h3>
                    <p>Montevideo, Uruguay</p>
                </div>
                <div class="footer-col col-md-4">
                    <h3>Connect</h3>
                    <ul class="list-inline">
                        <li>
                            <!-- <a class="medium" href="https://github.com/Ionasjospo" target="newwindow"><span
                                    class="fui-github"></span></a> -->
                        </li>
                        <li>
                            <!-- <a class="medium" href="https://www.linkedin.com/in/ionas-josponis/"
                                target="newwindow"><span class="fui-linkedin"></span></a> -->
                        </li>
                    </ul>
                </div>
                <div class="footer-col col-md-4">
                    <h3>Hire Us</h3>
                    <p>We are available for workshops</p>
                </div>
            </div>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-HoRfnjQe6LRgsZAWB7tF0/J9UvcrHJ/tDvkfjTcZ4IM3wb/SuRoGJb7nVLv9ej3M"
        crossorigin="anonymous"></script>
</body>

</html>