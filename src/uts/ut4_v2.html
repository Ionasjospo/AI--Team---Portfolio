<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>UT04 – Non-Linear Algorithms: Decision Trees and SVM</title>
    <link rel="stylesheet" href="../styles.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/flat-ui/2.2.2/css/flat-ui.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css">
</head>

<body>
    <nav class="navbar navbar-inverse navbar-fixed-top transparent">
        <div class="container">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar"
                    aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                </button>
                <a class="navbar-brand" href="../index.html"> Team #2</a>
            </div> <!-- .navbar-header -->
            <div class="collapse navbar-collapse" id="navbar">
                <ul class="nav navbar-nav navbar-right">
                    <li><a href="#about">About</a></li>
                    <li><a href="#portfolio">Portfolio</a></li>
                    <li><a href="#contact">Contact</a></li>
                </ul>
            </div> <!-- .navbar-collapse -->
        </div> <!-- .container -->
    </nav>
    <br>
    <br>
    <main data-spy="scroll" data-target=".navbar" data-offset="50">
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <h3 class="text-center">Decision Trees and Support Vector Machines</h3>
                <hr>
                <p class="intro-paragraph">
                    In Unit 4, we delve into two powerful machine learning approaches: Classification and Regression Trees (CART) and Support Vector Machines (SVM).
                    For CART, we explore model representation, learning from data to create decision rules, and using the model for predictions.
                    Additionally, we emphasize the importance of data preprocessing to ensure accurate and efficient model performance. 
                    For SVM, we study how the model represents data, learns from it to separate classes or predict outcomes, and applies the learned model to make predictions on new data. 
                    Data preparation is particularly crucial for SVM to optimize its performance and handle complex datasets effectively.
                </p>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                <div class="col-md-12 algorithm-box">
                    <h3>Decision trees</h3>
                    <p class="intro-paragraph">
                        <!-- https://www.ibm.com/topics/decision-trees -->
                        <b>What is a Decision tree?</b><br>
                        A decision tree is a non-parametric supervised learning algorithm, which is utilized for both classification and regression tasks. 
                        It has a hierarchical, tree structure, which consists of a root node, branches, internal nodes and leaf nodes. <br>
                        As you can see from the diagram below, a decision tree starts with a root node, which does not have any incoming branches. 
                        The outgoing branches from the root node then feed into the internal nodes, also known as decision nodes. 
                        Based on the available features, both node types conduct evaluations to form homogenous subsets, which are denoted by leaf nodes, or terminal nodes. 
                        The leaf nodes represent all the possible outcomes within the dataset.
                    </p>
                    
                    <p class="intro-paragraph">
                        <!-- https://www.ibm.com/topics/decision-trees -->
                        <b>Structure</b><br>
                        As you can see from the diagram below, a decision tree starts with a root node, which does not have any incoming branches. 
                        The outgoing branches from the root node then feed into the internal nodes, also known as decision nodes. 
                        Based on the available features, both node types conduct evaluations to form homogenous subsets, which are denoted by leaf nodes, or terminal nodes. 
                        The leaf nodes represent all the possible outcomes within the dataset.
                    </p>
                    <img src="../../Assets/ut4_v2_images/Decision-Tree_structure.png" class="img-fluid" style="width: 100%;">

                    <p class="intro-paragraph">
                        <!-- https://www.ibm.com/topics/decision-trees -->
                        <b>Types of decision trees</b><br>
                        <ul class="course-outline">
                            <li>ID3: This algorithm was created by <a href="https://dbpedia.org/page/Ross_Quinlan" target="_blank">Ross Quinlan</a> and leverages entropy and information gain as metrics to evaluate candidate splits. 
                                Some of Quinlan’s research on this algorithm from 1986 can be found <a href="https://hunch.net/~coms-4771/quinlan.pdf" target="_blank">here</a></li>
                            <li>C4.5: This algorithm is considered a later iteration of ID3, which was also developed by Quinlan. 
                                It can use information gain or gain ratios to evaluate split points within the decision trees. </li>
                            <li>CART: The term, CART, is an abbreviation for “classification and regression trees” and was introduced by Leo Breiman. This algorithm typically utilizes Gini impurity to identify the ideal attribute to split on. Gini impurity measures how often a randomly chosen attribute is misclassified. When evaluating using <a href="https://www.learndatasci.com/glossary/gini-impurity/"> Gini impurity</a>, a lower value is more ideal. </li>
                           
                        </ul>
                    </p>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                <div class="col-md-12 algorithm-box">
                    <h3>Support Vector Machines (SVM)</h3>
                    <p class="intro-paragraph">
                        <!-- https://www.geeksforgeeks.org/support-vector-machine-algorithm/ -->
                        A Support Vector Machine (SVM) is a powerful machine learning algorithm widely used for both linear and nonlinear classification, 
                        as well as regression and outlier detection tasks. SVMs are highly adaptable, making them suitable for various applications such as text classification, 
                        image classification, spam detection, handwriting identification, gene expression analysis, face detection, and anomaly detection. <br>
                        SVMs are particularly effective because they focus on finding the maximum separating hyperplane between the different classes in the target feature, 
                        making them robust for both binary and multiclass classification.
                        <br>
                        <br>
                        The primary objective of the SVM algorithm is to identify the optimal hyperplane in an N-dimensional space that can effectively separate data points into different classes in the feature space. 
                        The algorithm ensures that the margin between the closest points of different classes, known as support vectors, is maximized.
                        The dimension of the hyperplane depends on the number of features. 
                        For instance, if there are two input features, the hyperplane is simply a line, and if there are three input features, the hyperplane becomes a 2-D plane. As the number of features increases beyond three, the complexity of visualizing the hyperplane also increases.
                        <img src="../../Assets/ut4_v2_images/svm_hyperplane.jpg" class="img-fluid" style="width: 70%;">

                    </p>
                </div>
            </div>
        </div>

        <div class="container mt-2 mb-3">
            <h3 class="text-center">Take-home exercises</h3>
            <hr>
            <ul class="course-outline">
                <li><a href="ut4_v2_pds/ut4_v2_ta3.html">UT4_V2_TA3</a></li>
                <li><a href="ut4_v2_pds/ut4_v2_ta6.html">UT4_V2_TA6</a></li>
                <li><a href="ut4_v2_pds/ut4_v2_ta7.html">UT4_V2_TA7</a></li>
            </ul>
        </div>


        <div class="container mt-5 mb-3">
            <h3 class="text-center">Web bibliography</h3>
            <hr>
            <p>
                - https://www.ibm.com/topics/decision-trees <br>
                - https://www.geeksforgeeks.org/support-vector-machine-algorithm/ 
            </p>
        </div>

        <div class="text-center text-inverse navbar-inverse">
            <div class="container">
              <div class="row">
                <div class="footer-col col-md-4" id="contact">
                    <h3>Location</h3>
                        <p>Montevideo, Uruguay</p>
                </div> <!-- .footer-col -->
                <div class="footer-col col-md-4">
                    <h3>Connect</h3>
                    <ul class="list-inline">
                      <li>
                           <a class="medium" href="https://github.com/Ionasjospo" target="newwindow"><span class="fui-github"></span></a>
                      </li>
                      <li>
                          <a class="medium" href="https://www.linkedin.com/in/ionas-josponis/" target="newwindow"><span class="fui-linkedin"></span></a>
                      </li>
                    </ul>
                </div> <!-- .footer-col -->
                <div class="footer-col col-md-4">
                    <h3>Hire Us</h3>
                    <p>We are available for workshops</p>
                </div> <!-- .footer-col -->
              </div> <!-- .row -->
            </div> <!-- .container --> 
          </div> <!--  -->
        </div>
    </main>
</body>

</html>




<!-- https://codepen.io/eddyerburgh/pen/oxwXjx -->